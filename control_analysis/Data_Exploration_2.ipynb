{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script is part of the control analysis part of the project and it is used to check if we can consider all the trajectories in the dataset to come from the same distribution. Hence, for each trajectory we check that all the values of each dimension are part of the distributions that can be considered to be part of the same distribution. For this purpose, K-S test is employed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io\n",
    "import itertools as it\n",
    "import scipy.special as psi\n",
    "plt.style.use('classic')\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.integrate import quad\n",
    "from scipy.io import savemat\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sampling = 60\n",
    "modes = ['normal', 'drug']\n",
    "root_dir = '/rds/general/user/lr4617/home/4th_Year_Project/CAPTURE_rat_multidimensional/raw_data/'\n",
    "# load entire high-dimensional trajectories\n",
    "cnt = 0\n",
    "lengths = []\n",
    "for mode in modes:\n",
    "    trajs = os.listdir(root_dir + mode + '/' )\n",
    "    for traj_n in trajs:\n",
    "        if traj_n != '.ipynb_checkpoints': \n",
    "            # loading entire high-dimensional trajectory\n",
    "            path = root_dir + mode + '/' + traj_n + '/' + 'trajectories_na/'\n",
    "            trajectories = os.listdir(path)\n",
    "            # removing NaN columns\n",
    "            nan_cols = []\n",
    "            for i, time_bin in enumerate(trajectories):\n",
    "                if time_bin != 'behavs' and time_bin != '.ipynb_checkpoints':\n",
    "                    trajectory = loadmat(path + time_bin)\n",
    "                    trajectory = trajectory['trajectory'] \n",
    "                    for i in range(trajectory.shape[1]):\n",
    "                        if np.isnan(trajectory[:, i]).all():\n",
    "                            nan_cols.append(i)\n",
    "\n",
    "            # create entire trajectory\n",
    "            nan_cols = np.asarray(nan_cols)\n",
    "            if nan_cols.size > 0:\n",
    "                if len(np.where(nan_cols==nan_cols[0])[0])*3 == len(nan_cols):\n",
    "                    all_trajectories =  np.zeros( (int((trajectory.shape[0]*len(trajectories))/sub_sampling), trajectory.shape[1]-len(nan_cols)) )\n",
    "            else:\n",
    "                all_trajectories = np.zeros( (int((trajectory.shape[0]*len(trajectories))/sub_sampling), trajectory.shape[1]) )\n",
    "\n",
    "            for i, time_bin in enumerate(trajectories):\n",
    "                if time_bin != 'behavs' and time_bin != '.ipynb_checkpoints':\n",
    "                    trajectory = loadmat(path + time_bin)\n",
    "                    trajectory = trajectory['trajectory'] \n",
    "                    idx = np.round(np.arange(0, trajectory.shape[0], sub_sampling)).astype(int)\n",
    "                    trajectory = trajectory[idx]\n",
    "                    idx_2 = i*trajectory.shape[0]\n",
    "                    all_trajectories[idx_2:idx_2+trajectory.shape[0], 0:trajectory.shape[1]] = trajectory\n",
    "                    \n",
    "            print(all_trajectories.shape)\n",
    "            \n",
    "            # convert nan to number when not it is a sparse recurrence (not an entire COLUMN)\n",
    "            all_trajectories = np.nan_to_num(all_trajectories)\n",
    "            lengths.append(all_trajectories.shape[0])\n",
    "                        \n",
    "            # append trajectory to all trajectories\n",
    "            if cnt==0:\n",
    "                rats = all_trajectories\n",
    "            if cnt>0:\n",
    "                rats = np.concatenate((rats, all_trajectories), axis=0)\n",
    "                \n",
    "            cnt += 1\n",
    "            \n",
    "            print(rats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-S Test same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(*argv):\n",
    "    '''\n",
    "    input: \n",
    "        - 1D sequence of rv observations\n",
    "    return: \n",
    "        - probability vector\n",
    "    '''\n",
    "    n_args = len(argv)\n",
    "    if n_args == 1:\n",
    "        sequence = argv[0]\n",
    "        decimals = 1\n",
    "        size = 0\n",
    "        \n",
    "    if n_args == 2:\n",
    "        sequence = argv[0]\n",
    "        decimals = argv[1]\n",
    "        size = 0\n",
    "    \n",
    "    if n_args == 3:\n",
    "        sequence = argv[0]\n",
    "        decimals = argv[1]\n",
    "        size = argv[2]\n",
    "    \n",
    "    if len(sequence.shape) > 1 and (sequence.shape[0] < sequence.shape[1]):\n",
    "        sequence = np.transpose(sequence)\n",
    "    \n",
    "    # round input sequence to avoid sparse probability vector\n",
    "    sequence = np.round(sequence, decimals)\n",
    "    unique = np.unique(sequence, axis=0)\n",
    "    n_unique = len(unique)\n",
    "\n",
    "    # fill probability vector\n",
    "    if size == 0:\n",
    "        prob_vector = np.zeros((n_unique, ))\n",
    "    else:\n",
    "        prob_vector = np.zeros((size, ))\n",
    "\n",
    "    for row in sequence:\n",
    "        if len(sequence.shape) > 1:\n",
    "            occurrences = len(np.where(np.all(np.isclose(sequence, row), axis=1))[0])\n",
    "            idx = np.where(np.all(np.isclose(unique, row), axis=1))[0][0]\n",
    "        else:\n",
    "            occurrences = len(np.where(np.isclose(sequence, row))[0])\n",
    "            idx = np.where(np.isclose(unique, row))[0][0]\n",
    "            \n",
    "        if prob_vector[idx] == 0:\n",
    "            prob_vector[idx] = occurrences/(sequence.shape[0])\n",
    "            \n",
    "    return prob_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCULATING PROBABILITY VECTORS\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "33\n",
      "36\n",
      "39\n",
      "42\n",
      "45\n",
      "48\n",
      "51\n",
      "54\n",
      "57\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# probability vectors calculation\n",
    "print(\"CALCULATING PROBABILITY VECTORS\")\n",
    "truncation_decimal = 1\n",
    "dims = np.arange(0, rats.shape[1], 3)\n",
    "which = np.zeros((1, len(dims)))\n",
    "n_rats = len(lengths)\n",
    "\n",
    "for dim in dims:\n",
    "    print(dim)\n",
    "    probs = np.zeros((n_rats, max_size))\n",
    "    for i in range(n_rats):\n",
    "        sequence = rats[0:lengths[i], dim:dim+3]\n",
    "        # round input sequence to avoid sparse probability vector\n",
    "        sequence = np.round(sequence, truncation_decimal)\n",
    "        unique = np.unique(sequence, axis=0)\n",
    "        n_unique = len(unique)\n",
    "        if n_unique > max_:\n",
    "            max_ = n_unique\n",
    "    \n",
    "for dim in dims:\n",
    "    probs = np.zeros((n_rats, max_))\n",
    "    for i in range(n_rats):\n",
    "        print(i)\n",
    "        sequence = rats[0:lengths[i], dim:dim+3]\n",
    "        prob_vector = probability(sequence, truncation_decimal, max_)\n",
    "        probs[i, :] = prob_vector\n",
    "\n",
    "    # fill ks matrix \n",
    "    print(\"CALCULATING K-S MATRIX\")\n",
    "    # \"ks_matrix\" is quadratic and symmetric (A=A')\n",
    "    ks_matrix = np.zeros((n_rats, n_rats))\n",
    "    significance_level = 0.05\n",
    "    for ii in range(n_rats):\n",
    "        for jj in range(n_rats):\n",
    "            _, p_value = stats.ks_2samp(probs[ii, :], probs[jj, :])\n",
    "            if p_value<significance_level:\n",
    "                p_value = (round(p_value * 10**(truncation_decimal)))/(10**truncation_decimal)\n",
    "                ks_matrix[ii, jj] = p_value\n",
    "            elif p_value>=significance_level:\n",
    "                p_value = (round(p_value * 10**(truncation_decimal)))/(10**truncation_decimal)\n",
    "                ks_matrix[ii, jj] = p_value\n",
    "\n",
    "    which[dim] = np.all(ks_matrix == ks_matrix[0])\n",
    "    print(trajs)\n",
    "    print(ks_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prj_env_conda]",
   "language": "python",
   "name": "conda-env-prj_env_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
